{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "clustering pointcloud file: ./lidar_data/frame1.pcd.bin\n",
      "iters = 39.524008\n",
      "[ 0  0  1 ...  2 -1  2]\n",
      "clustering pointcloud file: ./lidar_data/frame2.pcd.bin\n",
      "iters = 46.815199\n",
      "[0 1 2 ... 1 1 1]\n",
      "clustering pointcloud file: ./lidar_data/frame3.pcd.bin\n",
      "iters = 70.178442\n",
      "[ 0  0  0 ...  1 -1 -1]\n",
      "clustering pointcloud file: ./lidar_data/frame4.pcd.bin\n",
      "iters = 79.978022\n",
      "[0 0 0 ... 1 2 5]\n",
      "clustering pointcloud file: ./lidar_data/frame5.pcd.bin\n",
      "iters = 63.093767\n",
      "[0 0 1 ... 0 0 0]\n",
      "clustering pointcloud file: ./lidar_data/frame6.pcd.bin\n",
      "iters = 49.091691\n",
      "[0 1 2 ... 3 4 3]\n",
      "clustering pointcloud file: ./lidar_data/frame7.pcd.bin\n",
      "iters = 43.920390\n",
      "[0 1 1 ... 2 3 3]\n",
      "clustering pointcloud file: ./lidar_data/frame8.pcd.bin\n",
      "iters = 46.885209\n",
      "[0 1 2 ... 3 5 4]\n",
      "clustering pointcloud file: ./lidar_data/frame9.pcd.bin\n",
      "iters = 42.350966\n",
      "[0 1 1 ... 1 1 1]\n",
      "clustering pointcloud file: ./lidar_data/frame10.pcd.bin\n",
      "iters = 42.268533\n",
      "[0 1 1 ... 2 2 2]\n",
      "Write successfully!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Jan 25 16:44:52 2023\n",
    "\n",
    "@author: cyh\n",
    "\"\"\"\n",
    "\n",
    "# function：\n",
    "#     1. load pointcloud data\n",
    "#     2. filter the ground pointcloud\n",
    "#     3. do clustering\n",
    "\n",
    "# # If run in vscode, change the path to site-packages in anaconda env\n",
    "# import sys\n",
    "# sys.path.append('/home/cyh/anaconda3/lib/python3.8/site-packages')\n",
    "\n",
    "# import\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import struct\n",
    "from sklearn import cluster, datasets, mixture\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import DataFrame\n",
    "from pyntcloud import PyntCloud\n",
    "import math\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import OPTICS\n",
    "from sklearn.cluster import Birch, AgglomerativeClustering\n",
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import json\n",
    "\n",
    "\n",
    "# visualize using matplotlib\n",
    "def Point_Cloud_Show(points):\n",
    "    fig = plt.figure(dpi=150)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    ax.scatter(points[:, 0], points[:, 1], points[:, 2], cmap='spectral', s=2, linewidths=0, alpha=1, marker=\".\")\n",
    "    plt.title('Point Cloud')\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    ax.set_zlabel('z')\n",
    "    plt.show()\n",
    "\n",
    "# read pointcloud data from file\n",
    "# Input:\n",
    "#     path: file path\n",
    "# Output:\n",
    "#     pointcloud array\n",
    "def read_velodyne_bin(path):\n",
    "    '''\n",
    "    :param path:\n",
    "    :return: homography matrix of the point cloud, N*3\n",
    "    '''\n",
    "    file_data = np.fromfile(path, dtype=np.float32)\n",
    "    points = file_data.reshape((-1, 5))[:, :3]\n",
    "    return points\n",
    "\n",
    "# filter the ground pointcloud\n",
    "# Input:\n",
    "#     data: one frame of pointcloud\n",
    "# Output:\n",
    "#     segmengted_cloud: pointcloud after filtering\n",
    "def ground_segmentation(data):\n",
    "    # initialize data\n",
    "    idx_segmented = []\n",
    "    segmented_cloud = []\n",
    "    iters = 100     # maximum iteration  \n",
    "    sigma = 0.4     # maximum accepted error between data and model 数据和模型之间可接受的最大差值  \n",
    "    ## plane model:  aX + bY + cZ +D= 0\n",
    "    best_a = 0\n",
    "    best_b = 0\n",
    "    best_c = 0\n",
    "    best_d = 0\n",
    "    pretotal = 0    # number of inliers in last iteration\n",
    "    P = 0.99        # the probability of getting the correct model 希望的到正确模型的概率\n",
    "    n = len(data)   # number of points \n",
    "    outline_ratio = 0.6   #e: outline_ratio  \n",
    "    for i in range(iters):\n",
    "        ground_cloud = []\n",
    "        idx_ground = []\n",
    "        # step1 choose the smallest datset to estimate the model, 3 points for a plane\n",
    "        # 选择可以估计出模型的最小数据集，对于平面拟合来说，就是三个点\n",
    "        sample_index = random.sample(range(n),3)    # randomly select 3 points from dataset\n",
    "        point1 = data[sample_index[0]]\n",
    "        point2 = data[sample_index[1]]\n",
    "        point3 = data[sample_index[2]]\n",
    "        # step2 solve the model\n",
    "        ## first solve the normal vector 先求解法向量\n",
    "        point1_2 = (point1-point2)      # vector poin1 -> point2\n",
    "        point1_3 = (point1-point3)      # vector poin1 -> point3\n",
    "        N = np.cross(point1_3,point1_2)            # get the normal vector of plane 向量叉乘求解 平面法向量\n",
    "        ## slove model parameter a,b,c,d\n",
    "        a = N[0]\n",
    "        b = N[1]\n",
    "        c = N[2]\n",
    "        d = -N.dot(point1)\n",
    "        # step3 use all the data to count the number of inliers \n",
    "        # 将所有数据带入模型，计算出“内点”的数目；(累加在一定误差范围内的适合当前迭代推出模型的数据)\n",
    "        total_inlier = 0\n",
    "        pointn_1 = (data - point1)    # sample（三点）外的点 与 sample内的三点其中一点 所构成的向量\n",
    "        distance = abs(pointn_1.dot(N))/ np.linalg.norm(N)     # distance\n",
    "        # judge the inliers by distance\n",
    "        idx_ground = (distance <= sigma)\n",
    "        total_inlier = np.sum(idx_ground == True)    # number of inliers\n",
    "        # compare the performance of model \n",
    "        if total_inlier > pretotal:                                           #     log(1 - p)\n",
    "            iters = math.log(1 - P) / math.log(1 - pow(total_inlier / n, 3))  #N = ------------\n",
    "            pretotal = total_inlier                                               #log(1-[(1-e)**s])\n",
    "            # the best model param\n",
    "            best_a = a\n",
    "            best_b = b\n",
    "            best_c = c\n",
    "            best_d = d\n",
    "\n",
    "        # enough inliers?\n",
    "        if total_inlier > n*(1-outline_ratio):\n",
    "            break\n",
    "    print(\"iters = %f\" %iters)\n",
    "    # points after segmentation\n",
    "    idx_segmented = np.logical_not(idx_ground)\n",
    "    ground_cloud = data[idx_ground]\n",
    "    segmented_cloud = data[idx_segmented]\n",
    "    return ground_cloud,segmented_cloud\n",
    "\n",
    "\n",
    "# do clustering\n",
    "# Input:\n",
    "#     data: cloud points without ground cloud\n",
    "# Output:\n",
    "#     clusters_index： class index of every points\n",
    "def dbscan_clustering(data):\n",
    "    # sklearn dbscan\n",
    "    clust = DBSCAN(eps=0.5,min_samples=10,n_jobs=-1)\n",
    "    cluster_index = clust.fit_predict(data)\n",
    "\n",
    "    print(cluster_index)\n",
    "    return cluster_index\n",
    "\n",
    "\n",
    "def optics_clustering(data):\n",
    "    # sklearn optics\n",
    "    clust = OPTICS(min_samples=10, n_jobs=-1)\n",
    "    cluster_index = clust.fit_predict(data)\n",
    "\n",
    "    # plot the reachability figure by OPTICS\n",
    "    space = np.arange(len(data))\n",
    "    reachability = clust.reachability_[clust.ordering_]\n",
    "    labels = clust.labels_[clust.ordering_]\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    fig,ax = plt.subplots(1,1)\n",
    "    ax.plot(space[labels >= 0], reachability[labels >= 0], \"r.\", alpha=0.1)\n",
    "    ax.plot(space[labels == -1], reachability[labels == -1], \"k.\", alpha=0.05)\n",
    "    ax.set_ylabel(\"Reachability (epsilon distance)\")\n",
    "    ax.set_title(\"Reachability Plot\")\n",
    "    plt.show()\n",
    "\n",
    "    print(cluster_index)\n",
    "\n",
    "    n_clusters_ = len(set(cluster_index)) - (1 if -1 in cluster_index else 0)\n",
    "    n_noise_ = list(cluster_index).count(-1)\n",
    "\n",
    "    print(n_clusters_)\n",
    "    print(n_noise_)\n",
    "    \n",
    "    return cluster_index\n",
    "\n",
    "\n",
    "def birch_clustering(data):\n",
    "    # sklearn birch\n",
    "    cluster_index = Birch(threshold=0.5,branching_factor=50,n_clusters=100).fit_predict(data)\n",
    "\n",
    "    print(cluster_index)\n",
    "\n",
    "    n_clusters_ = len(set(cluster_index)) - (1 if -1 in cluster_index else 0)\n",
    "    n_noise_ = list(cluster_index).count(-1)\n",
    "\n",
    "    print(n_clusters_)\n",
    "    print(n_noise_)\n",
    "    \n",
    "    return cluster_index\n",
    "\n",
    "\n",
    "def hierarchical_clustering(data):\n",
    "    # sklearn agglomerativeClustering\n",
    "    cluster_index = AgglomerativeClustering(n_clusters=100).fit_predict(data)\n",
    "    \n",
    "    print(cluster_index)\n",
    "\n",
    "    n_clusters_ = len(set(cluster_index)) - (1 if -1 in cluster_index else 0)\n",
    "    n_noise_ = list(cluster_index).count(-1)\n",
    "\n",
    "    print(n_clusters_)\n",
    "    print(n_noise_)\n",
    "    \n",
    "    return cluster_index\n",
    "\n",
    "\n",
    "def kmeans_clustering(data):\n",
    "    # sklearn kmeans\n",
    "    cluster_index = KMeans(n_clusters=100,tol=0.001).fit_predict(data)\n",
    "\n",
    "    print(cluster_index)\n",
    "    return cluster_index\n",
    "\n",
    "\n",
    "def meanshift_clustering(data):\n",
    "    # sklearn meanshift\n",
    "    bandwidth = estimate_bandwidth(data, quantile=0.01,n_samples=1000)\n",
    "    clust = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    cluster_index = clust.fit_predict(data)\n",
    "\n",
    "    print(cluster_index)\n",
    "    return cluster_index\n",
    "\n",
    "\n",
    "# visualize clustering results with different color\n",
    "# def plot_clusters(segmented_ground, segmented_cloud, cluster_index, bbox):\n",
    "def plot_clusters(segmented_ground, segmented_cloud, cluster_index, bbox, min_boundList, max_boundList):\n",
    "    \n",
    "    # Visualize segmentation results using Open3D\n",
    "    def colormap(c, num_clusters):\n",
    "        # Colormap for segmentation result\n",
    "        # outlier:\n",
    "        if c == -1:\n",
    "            color = [1]*3\n",
    "        # surrouding object:\n",
    "        else:\n",
    "            color = [0.5] * 3\n",
    "            color[c % 3] = c/(num_clusters*1.1)\n",
    "\n",
    "        return color\n",
    "    \n",
    "    # list for plot\n",
    "    plot_list = []\n",
    "\n",
    "    # ground element:\n",
    "    pcd_ground = o3d.geometry.PointCloud()\n",
    "    pcd_ground.points = o3d.utility.Vector3dVector(segmented_ground)\n",
    "    pcd_ground.colors = o3d.utility.Vector3dVector(\n",
    "        [\n",
    "            [0, 0, 255] for i in range(segmented_ground.shape[0])\n",
    "        ]\n",
    "    )\n",
    "    plot_list.append(pcd_ground)\n",
    "\n",
    "    # surrounding object elements:\n",
    "    pcd_objects = o3d.geometry.PointCloud()\n",
    "    pcd_objects.points = o3d.utility.Vector3dVector(segmented_cloud)\n",
    "    num_clusters = max(cluster_index) + 1\n",
    "    pcd_objects.colors = o3d.utility.Vector3dVector(\n",
    "        [\n",
    "            colormap(c, num_clusters) for c in cluster_index\n",
    "        ]\n",
    "    )\n",
    "    plot_list.append(pcd_objects)\n",
    "    \n",
    "    # bounding box\n",
    "    # bbox: [position–x, position–y , position–z , size-x, size-y, size-z, class]\n",
    "    for i in range(len(bbox)):\n",
    "        bounding_box = o3d.geometry.AxisAlignedBoundingBox()\n",
    "        \n",
    "        # min_bound = [bbox[i][0] - math.ceil(bbox[i][3] / 2), bbox[i][1] - math.ceil(bbox[i][4] / 2), bbox[i][2] - math.ceil(bbox[i][5] / 2)]\n",
    "        # max_bound = [bbox[i][0] + math.ceil(bbox[i][3] / 2), bbox[i][1] + math.ceil(bbox[i][4] / 2), bbox[i][2] + math.ceil(bbox[i][5] / 2)]\n",
    "        min_bound = [min_boundList[i][0], min_boundList[i][1], min_boundList[i][2]]\n",
    "        max_bound = [max_boundList[i][0], max_boundList[i][1], max_boundList[i][2]]\n",
    "\n",
    "        bounding_box.min_bound = min_bound\n",
    "        bounding_box.max_bound = max_bound\n",
    "        bounding_box.color = colormap(bbox[i][6], num_clusters)\n",
    "        \n",
    "        plot_list.append(bounding_box)\n",
    "        \n",
    "    \n",
    "\n",
    "    # visualize\n",
    "    o3d.visualization.draw_geometries(plot_list)\n",
    "    # o3d.visualization.draw_geometries([pcd_ground, pcd_objects, bounding_box, bounding_box2])\n",
    "\n",
    "    \n",
    "\n",
    "def main():\n",
    "    iteration_num = 10    # num of files\n",
    "    \n",
    "    res = {}\n",
    "\n",
    "    # used method, default='dbscan'\n",
    "    # other methods: 'optics', 'birch', 'hierarchical', 'kmeans', 'meanshift'\n",
    "    cluster_method = 'dbscan'\n",
    "\n",
    "    for i in range(iteration_num):\n",
    "        # filename = '/home/cyh/文档/nus/semester2/ME5413/HW1/me5413_homework1/me5413/1_lidar/lidar_data/frame' + \\\n",
    "        #         str(i+1) + '.pcd.bin'\n",
    "        filename = './lidar_data/frame' + str(i+1) + '.pcd.bin'\n",
    "        print('clustering pointcloud file:', filename)\n",
    "        \n",
    "        \n",
    "        origin_points = read_velodyne_bin(filename)     # read data\n",
    "        origin_points_df = DataFrame(origin_points,columns=['x', 'y', 'z'])  # [0,3)\n",
    "        point_cloud_pynt = PyntCloud(origin_points_df)  # store in structs\n",
    "        point_cloud_o3d = point_cloud_pynt.to_instance(\"open3d\", mesh=False) # to instance\n",
    "    \n",
    "        # # show initial cloudpoints\n",
    "        # o3d.visualization.draw_geometries([point_cloud_o3d])\n",
    "\n",
    "    \n",
    "        # ground segmentation\n",
    "        ground_points, segmented_points = ground_segmentation(data=origin_points)\n",
    "\n",
    "\n",
    "        # ground_points_df = DataFrame(ground_points, columns=['x', 'y', 'z'])  \n",
    "        # point_cloud_pynt_ground = PyntCloud(ground_points_df)  \n",
    "        # point_cloud_o3d_ground = point_cloud_pynt_ground.to_instance(\"open3d\", mesh=False) \n",
    "        # point_cloud_o3d_ground.paint_uniform_color([0, 0, 255])\n",
    "\n",
    "        # # show groud cloudpoints\n",
    "        # o3d.visualization.draw_geometries([point_cloud_o3d_ground])\n",
    "        \n",
    "        # do clustering\n",
    "        if cluster_method == 'dbscan':\n",
    "            # DBSCAN\n",
    "            cluster_index = dbscan_clustering(segmented_points)\n",
    "        elif cluster_method == 'optics':\n",
    "            # OPTICS\n",
    "            cluster_index = optics_clustering(segmented_points)\n",
    "        elif cluster_method == 'meanshift':\n",
    "            # Meanshift\n",
    "            cluster_index = meanshift_clustering(segmented_points)\n",
    "        elif cluster_method == 'birch':\n",
    "            # Birch\n",
    "            cluster_index = birch_clustering(segmented_points)\n",
    "        elif cluster_method == 'kmeans':\n",
    "            # Kmeans\n",
    "            cluster_index = kmeans_clustering(segmented_points)\n",
    "        elif cluster_method == 'hierarchical':\n",
    "            # Hierarchical\n",
    "            cluster_index = hierarchical_clustering(segmented_points)\n",
    "        \n",
    "        \n",
    "        # add bounding box\n",
    "        # position–x, position–y , position–z , size-x, size-y, size-z, class, confidence\n",
    "        bbox = []\n",
    "        min_boundList = []\n",
    "        max_boundList = []\n",
    "        \n",
    "        for j in range(max(cluster_index) + 1):\n",
    "            \n",
    "            # points of class j\n",
    "            points_inClass = np.argwhere(cluster_index == j)\n",
    "            \n",
    "            # num of points in class j\n",
    "            num = len(points_inClass)\n",
    "            \n",
    "            # xyz coordinates of points in class j\n",
    "            points_xyz = segmented_points[points_inClass].reshape(num, -1)\n",
    "            \n",
    "            # position–x, position–y , position–z of bbox\n",
    "            bbox_px = sum(points_xyz[:,0]) / num\n",
    "            bbox_py = sum(points_xyz[:,1]) / num\n",
    "            bbox_pz = sum(points_xyz[:,2]) / num\n",
    "            \n",
    "            # size-x, size-y, size-z of bbox\n",
    "            bbox_sx = max(points_xyz[:,0])-min(points_xyz[:,0])\n",
    "            bbox_sy = max(points_xyz[:,1])-min(points_xyz[:,1])\n",
    "            bbox_sz = max(points_xyz[:,2])-min(points_xyz[:,2])\n",
    "            \n",
    "            bbox.append([bbox_px, bbox_py, bbox_pz, bbox_sx, bbox_sy, bbox_sz, j])\n",
    "\n",
    "            min_boundList.append([min(points_xyz[:,0]), min(points_xyz[:,1]), min(points_xyz[:,2])])\n",
    "            max_boundList.append([max(points_xyz[:,0]), max(points_xyz[:,1]), max(points_xyz[:,2])])\n",
    "        \n",
    "        # show clustering results\n",
    "        # plot_clusters(ground_points, segmented_points, cluster_index, bbox)\n",
    "        plot_clusters(ground_points, segmented_points, cluster_index, bbox, min_boundList, max_boundList)\n",
    "        \n",
    "\n",
    "        # Number of clusters in labels, ignoring noise if present.\n",
    "        n_clusters_ = len(set(cluster_index)) - (1 if -1 in cluster_index else 0)\n",
    "        n_noise_ = list(cluster_index).count(-1)\n",
    "        \n",
    "        bbox = np.array(bbox).tolist()\n",
    "        \n",
    "        res['Lidar clustering results of frame' + str(i+1)] =       \\\n",
    "            {'Number of ground points': len(ground_points),         \\\n",
    "             'Number of surrounding points': len(segmented_points), \\\n",
    "             'Estimated number of clusters': n_clusters_,           \\\n",
    "             'Estimated number of noise points': n_noise_,          \\\n",
    "             'List of bounding box objects':bbox\n",
    "             }\n",
    "\n",
    "\n",
    "    new_dict = json.dumps(res, indent=1)\n",
    "    file_str = \"../Results/lidar_clustering.json\"\n",
    "    with open(file_str,\"w\", newline='\\n') as f:\n",
    "        f.write(new_dict)\n",
    "        print(\"Write successfully!\")\n",
    "        \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
